{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zYv7uqPv0iu",
        "outputId": "c229fc2e-474e-4fa1-995d-07d96975f557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"/content/drive/MyDrive/东乡语料文字部分1.txt\"\n",
        "path2 = \"/content/drive/MyDrive/东乡语料文字部分2.txt\" #located in `src/data` in the GitHub repository.\n",
        "\n",
        "with open(path1, \"r\", encoding=\"gbk\") as f1:\n",
        "    text1 = f1.read()\n",
        "\n",
        "with open(path2, \"r\", encoding=\"gbk\") as f2:\n",
        "    text2 = f2.read()"
      ],
      "metadata": {
        "id": "KNDJIakcwUov"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These two txt files are provided by local authorities and considered to be of high value because they were all compiled and collected locally by linguists for the purpose of creating bilingual textbooks (Mandarin/Dongxiang) for primary schools."
      ],
      "metadata": {
        "id": "9AAfrPtHd45m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "\n",
        "def split_lines(s: str):\n",
        "    if \"\\\\n\" in s and \"\\n\" not in s:\n",
        "        lines = s.split(\"\\\\n\")\n",
        "    else:\n",
        "        lines = s.splitlines()\n",
        "    lines = [ln.strip().strip(\"'\").strip() for ln in lines if ln.strip()]\n",
        "    return lines\n",
        "\n",
        "def clean_dxg(s: str) -> str:\n",
        "    s = re.sub(r\"[^A-Za-z\\s,\\.?]\", \" \", s)\n",
        "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
        "    s = re.sub(r\"[,.?]+$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def clean_zh(s: str) -> str:\n",
        "    s = re.sub(r\"[^\\u4e00-\\u9fff，。？]\", \"\", s)\n",
        "    s = re.sub(r\"[，。？]+$\", \"\", s)\n",
        "    return s\n",
        "\n",
        "def make_pairs(raw: str) -> pd.DataFrame:\n",
        "    lines = split_lines(raw)\n",
        "    pairs = []\n",
        "    for i in range(0, len(lines) - 1, 2):\n",
        "        dxg = clean_dxg(lines[i])\n",
        "        zh  = clean_zh(lines[i+1])\n",
        "        if dxg or zh:\n",
        "            pairs.append({\"Dongxiang\": dxg, \"Chinese\": zh})\n",
        "    return pd.DataFrame(pairs, columns=[\"Dongxiang\", \"Chinese\"])\n"
      ],
      "metadata": {
        "id": "E2Q3jvEIwgp-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pairs = make_pairs(text1)\n",
        "df_pairs2 = make_pairs(text2)\n",
        "df = pd.concat([df_pairs, df_pairs2])"
      ],
      "metadata": {
        "id": "atJd_5QPzB2y"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/df_interior.csv', index=False, encoding='utf-8-sig')"
      ],
      "metadata": {
        "id": "4xHBgkfo5oH6"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check"
      ],
      "metadata": {
        "id": "y-rkvT8U5CTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "df[\"Dongxiang_is_valid\"] = df[\"Dongxiang\"].apply(\n",
        "    lambda x: bool(re.fullmatch(r\"[A-Za-z\\s.,!?;:'\\\"\\-()]+\", str(x)))\n",
        ")\n",
        "df[\"Chinese_is_valid\"] = df[\"Chinese\"].apply(\n",
        "    lambda x: bool(re.fullmatch(r\"[\\u4e00-\\u9fff\\s。，、！？；：“”‘’（）《》【】—…,.!?;:'\\\"\\-()]+\", str(x)))\n",
        ")\n"
      ],
      "metadata": {
        "id": "nEIYwCZt2d0v"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Only English Character\", df[\"Dongxiang_is_valid\"].all())\n",
        "print(\"Only Chinese Character\", df[\"Chinese_is_valid\"].all())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgKCjz9H2lp2",
        "outputId": "fc1bf675-c2b7-49c8-f047-d24946f3e0e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Only English Character True\n",
            "Only Chinese Character True\n"
          ]
        }
      ]
    }
  ]
}